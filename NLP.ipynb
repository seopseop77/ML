{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAi0STFbp1QJfZYbREy6t/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seopseop77/ML/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ImKdCaZy8AXY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removemark(s): # 문자열에서 문장부호 제거 \n",
        "    marklist = ['.',',','?','!',':',';']\n",
        "    word = s\n",
        "    for mark in marklist:\n",
        "        word = word.replace(mark,'') \n",
        "    return word "
      ],
      "metadata": {
        "id": "Z970ZH-YyG-2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getBoW(s): # 문자열의 단어가 출현한 횟수를 value값으로 하는 딕셔너리 반환 \n",
        "    text_list = s.split()\n",
        "    bow_dic = {}\n",
        "    marklist = ['.',',','?','!',':',';']\n",
        "    \n",
        "    for i in text_list:\n",
        "        word = removemark(i)\n",
        "\n",
        "        if word in bow_dic.keys():\n",
        "            bow_dic[word] += 1 \n",
        "        else:\n",
        "            bow_dic[word] = 1 \n",
        "    \n",
        "    return bow_dic\n",
        "print(getBoW('John also likes to watch football games. I like to watch football, too.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKp3k-XDyKO3",
        "outputId": "40b270d2-21d3-4353-c1fc-1db4b7a56430"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'John': 1, 'also': 1, 'likes': 1, 'to': 2, 'watch': 2, 'football': 2, 'games': 1, 'I': 1, 'like': 1, 'too': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def n_gram(sentence,n): # 문장을 n 개 단어씩 묶어 출력 \n",
        "    \n",
        "    text_list = sentence.split()\n",
        "    wordlist = []\n",
        "    for i in range(len(text_list)-n+1):\n",
        "        st = ''\n",
        "        \n",
        "        for j in range(i,i+n):\n",
        "            st += removemark(text_list[j]) + ' ' \n",
        "        st = st.rstrip() \n",
        "        wordlist.append(st) \n",
        "    return wordlist \n",
        "\n",
        "print(n_gram(\"워너브라더스에서는 DCEU(DC  확장 유니버스)와 상관없는 조커 영화가 하나 더 제작된다.\",4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGW9_hCyyacF",
        "outputId": "91856f1b-126e-4e3d-d482-d2c1557a6c69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['워너브라더스에서는 DCEU(DC 확장 유니버스)와', 'DCEU(DC 확장 유니버스)와 상관없는', '확장 유니버스)와 상관없는 조커', '유니버스)와 상관없는 조커 영화가', '상관없는 조커 영화가 하나', '조커 영화가 하나 더', '영화가 하나 더 제작된다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqNC58UOrXkP",
        "outputId": "56ffd7c2-b7fb-4fea-9d40-6daa356bec50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n",
            "-------------------------\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 1 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n",
            "-------------------------\n",
            "[[1 0 0 1 0 0 0 0 2]]\n",
            "[[1 0 0 1 0 0 0 0 1]]\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "# 텍스트를 벡터로 변환 및 onehot 인코딩 \n",
        "\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\n",
        "     'This is the first document.',\n",
        "     'This document is the second document.',\n",
        "     'And this is the third one.',\n",
        "     'Is this the first document?',\n",
        " ]\n",
        "\n",
        "freq   = CountVectorizer()\n",
        "corpus_freq = freq.fit_transform(corpus)\n",
        "print(corpus_freq.toarray())\n",
        "print('-------------------------')\n",
        "\n",
        "onehot = Binarizer()\n",
        "corpus_onehot = onehot.fit_transform(corpus_freq.toarray())\n",
        "print(corpus_onehot)\n",
        "print('-------------------------')\n",
        "\n",
        "X = freq.transform(['and is this this two ten'])\n",
        "print(X.toarray())\n",
        "new_onehot = onehot.fit_transform(X.toarray())\n",
        "print(new_onehot)\n",
        "print('-------------------------')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def makeonehot(corpus): # 문장 리스트를 원핫 인코딩으로 변경하는 함수 \n",
        "  freq   = CountVectorizer()\n",
        "  corpus_freq = freq.fit_transform(corpus)\n",
        "\n",
        "  onehot = Binarizer()\n",
        "  corpus_onehot = onehot.fit_transform(corpus_freq.toarray())\n",
        "  \n",
        "  return corpus_onehot\n",
        "\n",
        "print(makeonehot(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxHZInzEtLjU",
        "outputId": "55b573f3-0a3b-4aeb-9b3a-687e33136191"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 1 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# jaccard index를 이용한 유사도 측정 및 챗봇 개발 \n",
        "\n",
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    x,y = [],[]\n",
        "    for word in a: \n",
        "      x.append(removemark(word))\n",
        "    for word in b: \n",
        "      y.append(removemark(word))\n",
        "    a = set(x)\n",
        "    b = set(y)\n",
        "\n",
        "    c = a.intersection(b)\n",
        "   \n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "\n",
        "conversations = {\n",
        "    \"hello\": \"Hello!\",\n",
        "    \"hi\": \"Hi!\",\n",
        "    \"how are you\": \"I'm doing well, thank you.\",\n",
        "    \"bye\": \"Goodbye!\",\n",
        "   \"what's your name\": \"My name is Chatbot!\",\n",
        "    \"how old are you\": \"I am a computer program, so I don't age.\",\n",
        "    \"what's the time\": \"I am not sure, can you please tell me the time?\",\n",
        "    \"what's your favorite color\": \"I am a machine, I do not have the ability to perceive or appreciate color\",\n",
        "    \"what's your favorite food\": \"I am a machine, I do not have the ability to eat or have preferences for food\",\n",
        "    \"what's the weather like today\": \"I am not sure, can you please tell me the current weather?\",\n",
        "    \"what's the capital of France\": \"The capital of France is Paris\",\n",
        "    \"what's the capital of Germany\": \"The capital of Germany is Berlin\",\n",
        "    \"what's the capital of Korea\": \"The capital of Korea is Seoul\",\n",
        "    \"what's the capital of India\": \"The capital of India is New Delhi\",\n",
        "   \"what's the population of France\": \"The population of France is approximately 67 million people\",\n",
        "    \"what's the population of Germany\": \"The population of Germany is approximately 83 million people\",\n",
        "    \"what's the population of Korea\": \"The population of China is approximately 50 million people\",\n",
        "    \"what's the population of India\": \"The population of India is approximately 1.4 billion people\",\n",
        "   \"What do you do\": \"I am a chatbot, my main function is to respond to your queries and converse with you.\"\n",
        "}\n",
        "\n",
        "def chat(message):\n",
        "    \n",
        "    if message in conversations.keys():\n",
        "        return conversations[message]\n",
        "    else:\n",
        "      max = 0 \n",
        "      maxsentence = ''\n",
        "      \n",
        "      for sentence in conversations.keys():\n",
        "        if jaccard(sentence,message) > max :\n",
        "          max = jaccard(sentence,message)\n",
        "          maxsentence = sentence \n",
        "      \n",
        "      if max > 0.3:\n",
        "        return conversations[maxsentence]\n",
        "\n",
        "      else:\n",
        "\n",
        "        return \"I'm sorry, I don't understand what you're saying.\"\n",
        "\n",
        "print(chat(\"hello\"))\n",
        "print(chat(\"hi\"))\n",
        "print(chat(\"how are you\"))\n",
        "print(chat(\"what is your name\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhjpskT01Yy5",
        "outputId": "61cdf172-90b4-4eb4-fbfc-dbbae070d229"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello!\n",
            "Hi!\n",
            "I'm doing well, thank you.\n",
            "My name is Chatbot!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine similarity를 이용하여 유사도 측정 및 챗봇 개발 \n",
        "\n",
        "def cal_cossimilarity(sen1,sen2):\n",
        "  array = makeonehot([sen1,sen2])\n",
        "  return np.dot(array[0],array[1])/(sum(array[0])*sum(array[1]))\n",
        "\n",
        "#print(cal_cossimilarity('hello bye','hello hi'))\n",
        "\n",
        "conversations = {\n",
        "    \"hello\": \"Hello!\",\n",
        "    \"hi\": \"Hi!\",\n",
        "    \"how are you\": \"I'm doing well, thank you.\",\n",
        "    \"bye\": \"Goodbye!\",\n",
        "   \"what's your name\": \"My name is Chatbot!\",\n",
        "    \"how old are you\": \"I am a computer program, so I don't age.\",\n",
        "    \"what's the time\": \"I am not sure, can you please tell me the time?\",\n",
        "    \"what's your favorite color\": \"I am a machine, I do not have the ability to perceive or appreciate color\",\n",
        "    \"what's your favorite food\": \"I am a machine, I do not have the ability to eat or have preferences for food\",\n",
        "    \"what's the weather like today\": \"I am not sure, can you please tell me the current weather?\",\n",
        "    \"what's the capital of France\": \"The capital of France is Paris\",\n",
        "    \"what's the capital of Germany\": \"The capital of Germany is Berlin\",\n",
        "    \"what's the capital of Korea\": \"The capital of Korea is Seoul\",\n",
        "    \"what's the capital of India\": \"The capital of India is New Delhi\",\n",
        "   \"what's the population of France\": \"The population of France is approximately 67 million people\",\n",
        "    \"what's the population of Germany\": \"The population of Germany is approximately 83 million people\",\n",
        "    \"what's the population of Korea\": \"The population of China is approximately 50 million people\",\n",
        "    \"what's the population of India\": \"The population of India is approximately 1.4 billion people\",\n",
        "   \"What do you do\": \"I am a chatbot, my main function is to respond to your queries and converse with you.\"\n",
        "}\n",
        "\n",
        "def chat(message):\n",
        "    \n",
        "    if message in conversations.keys():\n",
        "        return conversations[message]\n",
        "    else:\n",
        "      max = 0 \n",
        "      maxsentence = ''\n",
        "      \n",
        "      for sentence in conversations.keys():\n",
        "        if cal_cossimilarity(sentence,message) > max :\n",
        "          max = cal_cossimilarity(sentence,message)\n",
        "          maxsentence = sentence \n",
        "      \n",
        "      if max > 0.1:\n",
        "        return conversations[maxsentence]\n",
        "\n",
        "      else:\n",
        "\n",
        "        return \"I'm sorry, I don't understand what you're saying.\"\n",
        "\n",
        "print(chat(\"hello\"))\n",
        "print(chat(\"hi\"))\n",
        "print(chat(\"how are you\"))\n",
        "print(chat(\"bye!\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwxL3pOU5NBU",
        "outputId": "5c3ad33c-1bd5-43b5-eed9-b7b3dd537617"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello!\n",
            "Hi!\n",
            "I'm doing well, thank you.\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = [\n",
        "    \"I hated this movie so much.\",\n",
        "    \"The plot was incredibly boring.\",\n",
        "    \"I couldn't finish watching this.\",\n",
        "    \"The acting was terrible.\",\n",
        "    \"I'm not sure why anyone liked this movie.\",\n",
        "    \"This is my new favorite film.\",\n",
        "    \"I couldn't take my eyes off the screen!\",\n",
        "    \"I laughed so hard during this movie.\",\n",
        "    \"I want to see this again and again.\",\n",
        "    \"The ending was so satisfying.\",\n",
        "\n",
        "    \"I felt like I wasted my time with this one.\",\n",
        "\n",
        "    \"I was pleasantly surprised by this film.\",\n",
        "    \"I couldn't stop thinking about this movie afterwards.\",\n",
        "    \"This film was not what I was expecting.\",\n",
        "\n",
        "    \"I was completely drawn in by the story.\",\n",
        "    \"I couldn't stand the main character.\",\n",
        "\n",
        "    \"I thought the special effects were impressive.\",\n",
        "    \"This movie left me feeling so uplifted.\",\n",
        "\n",
        "    \"I was disappointed by the lack of character development.\",\n",
        "    \"The pacing of this movie was just perfect.\",\n",
        "    \"I thought the soundtrack was incredibly well done.\",\n",
        "    \"I hated the way the story was told.\",\n",
        "    \"I was so excited to see this movie.\",\n",
        "    \"I was let down by the acting.\",\n",
        "    \"I thought the cinematography was breathtaking.\",\n",
        "\n",
        "    \"This movie exceeded all of my expectations.\",\n",
        "    \"I was so pleased with the way everything was tied together.\",\n",
        "    \"I felt like I was watching a masterpiece.\"\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    0,  # negative\n",
        "    0,  # negative\n",
        "    0,  # negative\n",
        "    0,  # negative\n",
        "    0,  # negative\n",
        "    1,  # positive\n",
        "    1,  # positive\n",
        "    1,  # positive\n",
        "    1,  # positive\n",
        "    1,  # positive\n",
        "\n",
        "    0,  # negative\n",
        "\n",
        "    1,  # positive\n",
        "    1,  # positive\n",
        "    0,  # negative\n",
        "\n",
        "    1,  # positive\n",
        "    0,  # negative\n",
        "\n",
        "    1,  # positive\n",
        "    1,  # positive\n",
        "\n",
        "    0,  # negative\n",
        "    1,  # positive\n",
        "    1,  # positive\n",
        "    0,  # negative\n",
        "    1,  # positive\n",
        "    0,  # negative\n",
        "    1,  # positive\n",
        "\n",
        "    1,  # positive\n",
        "    1,  # positive\n",
        "    1   # positive\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "reviews_test = [\"A powerful and emotional film that tells a deeply moving story of hope, friendship, and redemption. The performances by actors are exceptional, and the direction is masterful.\",\n",
        "           \"A thrilling and suspenseful adventure with amazing special effects\",\n",
        "            \"A heartwarming tale that is both funny and emotional\",\n",
        "           \"A cinematic masterpiece with iconic performances and a gripping story\",\n",
        "           \"An unwatchable and poorly made film, with terrible acting and writing\",\n",
        "           \"A pointless and uninspired animation, with no redeeming qualities\",\n",
        "            \"A poorly executed and unfaithful adaptation of the original story\",\n",
        "           \"A forgettable and uninspired film with a lackluster cast\",\n",
        "           \"A mind-bending and well-crafted thriller with a shocking twist\",\n",
        "           \"A thrilling adventure movie with great special effects\"\n",
        "]\n",
        "labels_test = [1, 1, 1, 1, 0, 0, 0, 0, 1, 1]"
      ],
      "metadata": {
        "id": "TTbmpAVxZV0m"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "reviews_train = reviews\n",
        "reviews_test = reviews_test\n",
        "labels_train = labels\n",
        "labels_test = labels_test\n",
        "\n",
        "# bag-of-words representation\n",
        "vectorizer = CountVectorizer()\n",
        "reviews_train_features = vectorizer.fit_transform(reviews_train)\n",
        "reviews_test_features = vectorizer.transform(reviews_test)\n",
        "\n",
        "'''\n",
        "# Training a Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(reviews_train_features, labels_train)\n",
        "'''\n",
        "\n",
        "'''\n",
        "# Training a svm\n",
        "classifier = SVC(kernel='linear', C=1.0, random_state=1) \n",
        "classifier.fit(reviews_train_features, labels_train)\n",
        "'''\n",
        "\n",
        "'''\n",
        "# Training a logisticRegression\n",
        "classifier = LogisticRegression(solver='liblinear', multi_class='auto',C=100.0, random_state=78)\n",
        "classifier.fit(reviews_train_features, labels_train)\n",
        "'''\n",
        "\n",
        "\n",
        "# Training a KNN\n",
        "classifier = KNC(n_neighbors=1, p=2, metric='minkowski')\n",
        "classifier.fit(reviews_train_features, labels_train)\n",
        "\n",
        "\n",
        "'''\n",
        "# Training a decision tree\n",
        "classifier = DecisionTreeClassifier()\n",
        "classifier = classifier.fit(reviews_train_features, labels_train)\n",
        "'''\n",
        "\n",
        "# Evaluate\n",
        "predictions = classifier.predict(reviews_test_features)\n",
        "accuracy = accuracy_score(labels_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD-rk4U_ZOWl",
        "outputId": "d368a96a-1cd9-472e-d80d-336497818ebb"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive 분류기 구현 \n",
        "\n",
        "reviews = [   \n",
        "    ('fun,couple,love,love', 'comedy'),\n",
        "    ('fast,furious,shoot', 'action'),\n",
        "    ('couple,fly,fast,fun,fun', 'comedy'),\n",
        "    ('furious,shoot,shoot,fun', 'action'),\n",
        "    ('fly,fast,shoot,love', 'action')]\n",
        "\n",
        "\n",
        "def get_words_category(reviews):\n",
        "  action_words, comedy_words = [],[]\n",
        "  for words in reviews:\n",
        "    wordlist = words[0].split(',')\n",
        "    if words[1] == 'action':\n",
        "      action_words = action_words + wordlist\n",
        "    if words[1] == 'comedy':\n",
        "      comedy_words = comedy_words + wordlist  \n",
        "  \n",
        "  return action_words, comedy_words\n",
        "\n",
        "def predict (review, priorA, priorC, wordsA, wordsC):\n",
        "\n",
        "  number = len(set(wordsA+wordsC))\n",
        "  wordlist = review.split(',')\n",
        "  p_A,p_C = 1,1 \n",
        "  for word in wordlist:\n",
        "    p_A *= (wordsA.count(word)+1)/(len(wordsA)+number)\n",
        "    p_C *= (wordsC.count(word)+1)/(len(wordsC)+number)\n",
        "  if p_A >= p_C:\n",
        "    predicted_class = 'action'\n",
        "  else:\n",
        "    predicted_class  = 'comedy'\n",
        "    \n",
        "  return predicted_class\n",
        "\n",
        "     \n",
        "def get_prior (reviews):\n",
        "  prior_action, prior_comedy = 0,0\n",
        "  for words in reviews:\n",
        "    if words[1] == 'action':\n",
        "      prior_action += 1 \n",
        "    if words[1] == 'comedy':\n",
        "      prior_comedy += 1\n",
        "  sum = prior_comedy + prior_action \n",
        "  prior_action, prior_comedy = prior_action/sum, prior_comedy/sum\n",
        "  return prior_action, prior_comedy\n",
        "\n",
        "\n",
        "priorA, priorC = get_prior(reviews)\n",
        "wordListA, wordListC = get_words_category(reviews)\n",
        "review1 = 'fast,furious,shoot,love'\n",
        "review2 = 'fast,fun,fun,love,fun'\n",
        "print( review1 + ' belongs to '+ predict(review1, priorA, priorC, wordListA, wordListC))\n",
        "print( review2 + ' belongs to '+ predict(review2, priorA, priorC, wordListA, wordListC))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ysd4_Z7m3Uq",
        "outputId": "6cce9793-be90-4cc3-cc61-6b1c7a7b98fd"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fast,furious,shoot,love belongs to action\n",
            "fast,fun,fun,love,fun belongs to comedy\n"
          ]
        }
      ]
    }
  ]
}